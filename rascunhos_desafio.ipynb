{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio Detecção de objetos pequenos usando YOLO\n",
    "Vou usar esse notebook como rascunho para os códigos e testá-los também.\n",
    "\n",
    "Links de Apoio:\n",
    "- [YOLOv8 GitHub](https://github.com/ultralytics/ultralytics)\n",
    "- [Ultralytics docs](https://docs.ultralytics.com/)\n",
    "- Datasets e Modelos: [Roboflow](https://huggingface.co/), [Hugging Face](https://huggingface.co/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Códigos de início e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste pra ver se ta tudo funcionando\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\") # modelo pre-treinado\n",
    "\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")\n",
    "\n",
    "for result in results:\n",
    "    result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/julio/Dev/tests/ML/DesafioYOLO/imgs/0.jpg: 480x640 (no detections), 68.7ms\n",
      "Speed: 2.1ms preprocess, 68.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# teste com uma imagem\n",
    "\n",
    "img = \"imgs/0.jpg\"\n",
    "\n",
    "results = model(img, conf=0.5)\n",
    "\n",
    "for result in results:\n",
    "    result.show()\n",
    "\n",
    "# não da resultado nenhum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG (500, 381)\n",
      "\n",
      "WARNING ⚠️ imgsz=[500, 381] must be multiple of max stride 32, updating to [512, 384]\n",
      "0: 320x384 (no detections), 36.5ms\n",
      "Speed: 8.3ms preprocess, 36.5ms inference, 0.3ms postprocess per image at shape (1, 3, 320, 384)\n"
     ]
    }
   ],
   "source": [
    "# Teste setando o tamanho da imagem (imgsz) usando PIL\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"imgs/1.jpg\")\n",
    "print(img.format, img.size)\n",
    "\n",
    "results = model(img, imgsz=img.size)\n",
    "for result in results:\n",
    "    result.show()\n",
    "\n",
    "# tambem não da resultado nenhum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG (626, 441)\n",
      "\n",
      "0: 480x640 9 castors, 316.2ms\n",
      "Speed: 2.7ms preprocess, 316.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Usando um modelo de deteccao de plantas https://huggingface.co/foduucom/plant-leaf-detection-and-classification\n",
    "model = YOLO(\"models/best.pt\")\n",
    "\n",
    "img = Image.open(\"imgs/0.jpg\")\n",
    "print(img.format, img.size)\n",
    "\n",
    "results = model(img, augment=True)\n",
    "for result in results:\n",
    "    result.show()\n",
    "\n",
    "# melhor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ imgsz=[626, 441] must be multiple of max stride 32, updating to [640, 448]\n",
      "0: 320x448 (no detections), 1059.1ms\n",
      "Speed: 1.1ms preprocess, 1059.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 448)\n"
     ]
    }
   ],
   "source": [
    "# Usando o modelo YOLOv8x\n",
    "model = YOLO(\"models/yolov8x.pt\")\n",
    "\n",
    "results = model(img, imgsz=img.size, augment=True)\n",
    "for result in results:\n",
    "    result.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando SAHI pra melhorar a detecção de objetos pequenos\n",
    "[SAHI Framework](https://github.com/obss/sahi)\n",
    "\n",
    "SAHI (Slicing Aided Hyper Inference) é uma framework que basicamente divide a imagem dada como input em menores imagens e faz a detecção de objetos nessas imagens menores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sahi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 2 slices.\n"
     ]
    }
   ],
   "source": [
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_sliced_prediction\n",
    "\n",
    "model = AutoDetectionModel.from_pretrained(\n",
    "    model_type=\"yolov8\",\n",
    "    model_path=\"models/best.pt\",\n",
    "    confidence_threshold=0.3,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "result = get_sliced_prediction(\n",
    "    \"imgs/0.jpg\",\n",
    "    model,\n",
    "    slice_height=512,\n",
    "    slice_width=512,\n",
    "    overlap_height_ratio=0.1,\n",
    "    overlap_width_ratio=0.1\n",
    ")\n",
    "\n",
    "result.export_visuals(export_dir=\"exp/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando modelo com um Dataset customizado\n",
    "Usando o [Roboflow Universe](https://universe.roboflow.com/) com diversas imagens de folhas, criei um novo dataset que junta esses outros datasets e uso isso pra treinar um modelo YOLOv8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\".apikey\") as f:\n",
    "    os.environ[\"ROBOFLOW_API_KEY\"] = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.61, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    }
   ],
   "source": [
    "# Baixando dataset\n",
    "# ROBOFLOW_API_KEY é a chave da conta no Robotflow. Vou setar ela pelo terminal pra não ficar salvo aqui\n",
    "import os\n",
    "from roboflow import Roboflow\n",
    "\n",
    "rf_api_key = os.environ[\"ROBOFLOW_API_KEY\"]\n",
    "\n",
    "rf = Roboflow(api_key=rf_api_key)\n",
    "project = rf.workspace(\"jc-98d3n\").project(\"leaf-detection-h0stp\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/home/julio/Dev/tests/ML/DesafioYOLO/leaf-detection-1'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{dataset.location}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo treinando o modelo pre-treinado \"yolov8s.pt\"\n",
    "# meu computador não tem placa de vídeo então rodei isso no google colab\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "\n",
    "results = model.train(data=f\"{dataset.location}/data.yaml\", epochs=200, imgsz=640, patience=50, device=\"cpu\")\n",
    "\n",
    "# não funcionou pelo colab tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando um modelo de detecção do Universe Roboflow + SAHI\n",
    "Modelo usado: [link](https://universe.roboflow.com/rdgf/leaf-detection-a4rgd/model/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo já existente\n",
    "Modelo usado: [link](https://universe.roboflow.com/rdgf/leaf-detection-a4rgd/model/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy==1.26.4 roboflow==1.1.33 supervision opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "API_KEY = os.environ[\"ROBOFLOW_API_KEY\"]\n",
    "\n",
    "rf = Roboflow(api_key=API_KEY)\n",
    "project = rf.workspace().project(\"leaf-detection-a4rgd\")\n",
    "model = project.version(5).model\n",
    "\n",
    "def callback(image: np.ndarray) -> sv.Detections:\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".jpg\") as f:\n",
    "        cv2.imwrite(f.name, image)\n",
    "        result = model.predict(f.name, confidence=40, overlap=20).json()\n",
    "\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "    return detections\n",
    "\n",
    "image = cv2.imread(\"imgs/0.jpg\")\n",
    "\n",
    "slicer = sv.InferenceSlicer(callback=callback, slice_wh=(480, 480), overlap_ratio_wh=(0.1, 0.1))\n",
    "sliced_detections = slicer(image=image)\n",
    "\n",
    "prediction_count = len(sliced_detections.xyxy)\n",
    "print(f\"Counted {prediction_count} leafs\")\n",
    "\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "\n",
    "annotated_frame = box_annotator.annotate(\n",
    "    scene=image.copy(),\n",
    "    detections=sliced_detections,\n",
    ")\n",
    "\n",
    "annotated_frame = label_annotator.annotate(\n",
    "    scene=annotated_frame, detections=sliced_detections\n",
    ")\n",
    "\n",
    "\n",
    "sv.plot_image(image=annotated_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando um modelo próprio (treinado pelo Roboflow)\n",
    "[Link](https://universe.roboflow.com/jc-98d3n/leaf-detection-h0stp/model/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "API_KEY = os.environ[\"ROBOFLOW_API_KEY\"]\n",
    "\n",
    "rf = Roboflow(api_key=API_KEY)\n",
    "project = rf.workspace().project(\"leaf-detection-h0stp\")\n",
    "model = project.version(1).model\n",
    "\n",
    "def callback(image: np.ndarray) -> sv.Detections:\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".jpg\") as f:\n",
    "        cv2.imwrite(f.name, image)\n",
    "        result = model.predict(f.name, confidence=40, overlap=20).json()\n",
    "\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "    return detections\n",
    "\n",
    "image = cv2.imread(\"imgs/0.jpg\")\n",
    "\n",
    "slicer = sv.InferenceSlicer(callback=callback, slice_wh=(96, 96), overlap_ratio_wh=(0.2, 0.2))\n",
    "sliced_detections = slicer(image=image)\n",
    "\n",
    "prediction_count = len(sliced_detections.xyxy)\n",
    "print(f\"Counted {prediction_count} leafs\")\n",
    "\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "\n",
    "annotated_frame = box_annotator.annotate(\n",
    "    scene=image.copy(),\n",
    "    detections=sliced_detections,\n",
    ")\n",
    "\n",
    "annotated_frame = label_annotator.annotate(\n",
    "    scene=annotated_frame, detections=sliced_detections\n",
    ")\n",
    "\n",
    "\n",
    "sv.plot_image(image=annotated_frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
